{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pregunta 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chequeos previos de performance\n",
    "\n",
    "Para evitar tiempos de entrenamiento muy extensos es recomendable utilizar la **GPU** disponible en el sistema en lugar de la **CPU**, ya que posee la habilidad de realizar cálculos matemáticos de manera más eficiente. A continuación se verifica que se esté efectivamente utilizando la GPU en lugar de la CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Felipe\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 5394490448753632075\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 3178453401\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 18346702169759372435\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 980, pci bus id: 0000:01:00.0, compute capability: 5.2\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generación del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "import keras\n",
    "label_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "(x_train, y_train), (x_original_test, y_original_test) = cifar10.load_data()\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train)\n",
    "y_original_test = keras.utils.to_categorical(y_original_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generación de conjuntos de validación, test y entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 50000\n",
      "Test samples: 5000\n",
      "Validation samples: 5000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_test, x_val, y_test, y_val = train_test_split(x_original_test, y_original_test, test_size=0.5, random_state=42)\n",
    "\n",
    "\n",
    "print(\"Train samples: %d\" % len(x_train))\n",
    "print(\"Test samples: %d\" % len(x_test))\n",
    "print(\"Validation samples: %d\" % len(x_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cambios de dimensionalidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               2097664   \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 2,141,514\n",
      "Trainable params: 2,141,514\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "def define_convolutional(filter_size=3):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, (filter_size, filter_size), padding='same', input_shape=x_train.shape[1:]))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(64, (filter_size, filter_size), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(10))\n",
    "    model.add(Activation('softmax'))\n",
    "    return model\n",
    "model = define_convolutional()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pending to visualize the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Entrene la CNN definida en c) utilizando SGD. En este dataset, una tasa de aprendizaje “segura” es  η=104η=104  o inferior, pero durante las primeras epochs el entrenamiento resulta demasiado lento. Para resolver el problema aprenderemos a controlar la tasa de aprendizaje utilizada en el entrenamiento. Implemente la siguiente idea: deseamos partir con una tasa de aprendizaje  η=103η=103  y dividir por 2 ese valor cada 10 epochs. Suponga además que no queremos usar una tasa de aprendizaje menor a  η=105η=105 . Construya un gráfico que muestre los errores de entrenamiento, validación y pruebas como función del número de “epochs”, entrene con 25 epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento de red usando SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos el entrenamiento con un decay customizado definido en `step_decay`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 5000 samples\n",
      "Epoch 1/25\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 14.5062 - acc: 0.1000 - val_loss: 14.4998 - val_acc: 0.1004\n",
      "Epoch 2/25\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.4998 - val_acc: 0.1004\n",
      "Epoch 3/25\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.4998 - val_acc: 0.1004\n",
      "Epoch 4/25\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.4998 - val_acc: 0.1004\n",
      "Epoch 5/25\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.4998 - val_acc: 0.1004\n",
      "Epoch 6/25\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.4998 - val_acc: 0.1004\n",
      "Epoch 7/25\n",
      "50000/50000 [==============================] - 11s 215us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.4998 - val_acc: 0.1004\n",
      "Epoch 8/25\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.4998 - val_acc: 0.1004\n",
      "Epoch 9/25\n",
      "50000/50000 [==============================] - 11s 215us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.4998 - val_acc: 0.1004\n",
      "Epoch 10/25\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.4998 - val_acc: 0.1004\n",
      "Epoch 11/25\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.4998 - val_acc: 0.1004\n",
      "Epoch 12/25\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.4998 - val_acc: 0.1004\n",
      "Epoch 13/25\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.4998 - val_acc: 0.1004\n",
      "Epoch 14/25\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.4998 - val_acc: 0.1004\n",
      "Epoch 15/25\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.4998 - val_acc: 0.1004\n",
      "Epoch 16/25\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.4998 - val_acc: 0.1004\n",
      "Epoch 17/25\n",
      "50000/50000 [==============================] - 11s 215us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.4998 - val_acc: 0.1004\n",
      "Epoch 18/25\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.4998 - val_acc: 0.1004\n",
      "Epoch 19/25\n",
      "50000/50000 [==============================] - 11s 213us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.4998 - val_acc: 0.1004\n",
      "Epoch 20/25\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.4998 - val_acc: 0.1004\n",
      "Epoch 21/25\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.4998 - val_acc: 0.1004\n",
      "Epoch 22/25\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.4998 - val_acc: 0.1004\n",
      "Epoch 23/25\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.4998 - val_acc: 0.1004\n",
      "Epoch 24/25\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.4998 - val_acc: 0.1004\n",
      "Epoch 25/25\n",
      "50000/50000 [==============================] - 11s 215us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.4998 - val_acc: 0.1004\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import SGD, rmsprop\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "import math\n",
    "def step_decay(epoch):\n",
    "    initial_lrate = 0.001\n",
    "    lrate = initial_lrate * math.pow(0.5, math.floor((1+epoch)/5))\n",
    "    lrate = max(lrate,0.00001)\n",
    "    return lrate\n",
    "\n",
    "# Entrenamiento de la red\n",
    "model = define_convolutional()\n",
    "sgd = SGD(lr=0.0, momentum=0.9, decay=0.0)\n",
    "lrate = LearningRateScheduler(step_decay)\n",
    "model.compile(optimizer=sgd, loss=\"categorical_crossentropy\", metrics=[\"acc\"])\n",
    "history = model.fit(x_train, y_train, batch_size=32, epochs=25, validation_data=(x_test,y_test), shuffle=True, callbacks=[lrate])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento de red utilizando RMSProp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.\n",
      "Train on 50000 samples, validate on 5000 samples\n",
      "Epoch 1/25\n",
      "50000/50000 [==============================] - 13s 254us/step - loss: 14.5061 - acc: 0.1000 - val_loss: 14.4386 - val_acc: 0.1042\n",
      "Epoch 2/25\n",
      "50000/50000 [==============================] - 12s 249us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.4386 - val_acc: 0.1042\n",
      "Epoch 3/25\n",
      "50000/50000 [==============================] - 12s 249us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.4386 - val_acc: 0.1042\n",
      "Epoch 4/25\n",
      "50000/50000 [==============================] - 12s 249us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.4386 - val_acc: 0.1042\n",
      "Epoch 5/25\n",
      "50000/50000 [==============================] - 12s 249us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.4386 - val_acc: 0.1042\n",
      "Epoch 6/25\n",
      "50000/50000 [==============================] - 12s 248us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.4386 - val_acc: 0.1042\n",
      "Epoch 7/25\n",
      "50000/50000 [==============================] - 12s 249us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.4386 - val_acc: 0.1042\n",
      "Epoch 8/25\n",
      "50000/50000 [==============================] - 12s 250us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.4386 - val_acc: 0.1042\n",
      "Epoch 9/25\n",
      "50000/50000 [==============================] - 12s 249us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.4386 - val_acc: 0.1042\n",
      "Epoch 10/25\n",
      "50000/50000 [==============================] - 12s 249us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.4386 - val_acc: 0.1042\n",
      "Epoch 11/25\n",
      "50000/50000 [==============================] - 12s 249us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.4386 - val_acc: 0.1042\n",
      "Epoch 12/25\n",
      "50000/50000 [==============================] - 13s 250us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.4386 - val_acc: 0.1042\n",
      "Epoch 13/25\n",
      "50000/50000 [==============================] - 12s 250us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.4386 - val_acc: 0.1042\n",
      "Epoch 14/25\n",
      "50000/50000 [==============================] - 12s 250us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.4386 - val_acc: 0.1042\n",
      "Epoch 15/25\n",
      "50000/50000 [==============================] - 13s 251us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.4386 - val_acc: 0.1042\n",
      "Epoch 16/25\n",
      "50000/50000 [==============================] - 13s 251us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.4386 - val_acc: 0.1042\n",
      "Epoch 17/25\n",
      "50000/50000 [==============================] - 13s 251us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.4386 - val_acc: 0.1042\n",
      "Epoch 18/25\n",
      "50000/50000 [==============================] - 13s 251us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.4386 - val_acc: 0.1042\n",
      "Epoch 19/25\n",
      "50000/50000 [==============================] - 13s 250us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.4386 - val_acc: 0.1042\n",
      "Epoch 20/25\n",
      "50000/50000 [==============================] - 12s 250us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.4386 - val_acc: 0.1042\n",
      "Epoch 21/25\n",
      "50000/50000 [==============================] - 12s 250us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.4386 - val_acc: 0.1042\n",
      "Epoch 22/25\n",
      "50000/50000 [==============================] - 13s 251us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.4386 - val_acc: 0.1042\n",
      "Epoch 23/25\n",
      "50000/50000 [==============================] - 13s 251us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.4386 - val_acc: 0.1042\n",
      "Epoch 24/25\n",
      "50000/50000 [==============================] - 13s 250us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.4386 - val_acc: 0.1042\n",
      "Epoch 25/25\n",
      "50000/50000 [==============================] - 12s 250us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.4386 - val_acc: 0.1042\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import SGD, rmsprop\n",
    "model = define_convolutional()\n",
    "opt = rmsprop(lr=0.001, decay=1e-6)\n",
    "model.compile(optimizer=opt, loss=\"categorical_crossentropy\", metrics=[\"acc\"])\n",
    "history = model.fit(x_train, y_train,batch_size=32,epochs=25, validation_data=(x_test, y_test),shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f) Evalúe el efecto de modificar el tamaño de los filtros (de convolución) reportando la sensibilidad del error de pruebas a estos cambios en dos tipos de arquitecturas, una profunda y otra no. Presente un gráfico o tabla resumen. Por simplicidad entre durante sólo 15-20 epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Efecto del tamaño de los filtros de convolución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_shallow_convolutional(filter_size=3):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, (filter_size, filter_size), padding='same', input_shape=x_train.shape[1:]))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(10))\n",
    "    model.add(Activation('softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with filter size 2\n",
      "Training with filter size 3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "filter_results = {\n",
    "    \"shallow\": [],\n",
    "    \"deep\": []\n",
    "}\n",
    "\n",
    "filter_sizes = range(2, 9)\n",
    "\n",
    "for filter_size in filter_sizes:\n",
    "    print(\"Training with filter size %d\" % filter_size)\n",
    "    # Use the shallow first\n",
    "    model = define_shallow_convolutional(filter_size=filter_size)\n",
    "    model.compile(optimizer=sgd, loss=\"categorical_crossentropy\", metrics=[\"acc\"])\n",
    "    history = model.fit(x_train, y_train,batch_size=32,epochs=20, validation_data=(x_test, y_test),shuffle=True, verbose=False)\n",
    "    filter_results[\"shallow\"].append(history)\n",
    "    \n",
    "    # Deep one\n",
    "    model = define_convolutional(filter_size=filter_size)\n",
    "    model.compile(optimizer=sgd, loss=\"categorical_crossentropy\", metrics=[\"acc\"])\n",
    "    history = model.fit(x_train, y_train,batch_size=32,epochs=20, validation_data=(x_test, y_test),shuffle=True, verbose=False)\n",
    "    filter_results[\"deep\"].append(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "g)Se ha sugerido que la práctica bastante habitual de continuar una capa convolucional con una capa de pooling puede generar una reducción prematura de las dimensiones del patrón de entrada. Experimente con una arquitectura del tipo  C×C×P×C×C×P×F×F. Use 64 filtros para las primeras 2 capas convolucionales y 128 para las últimas dos. Reflexione sobre qué le parece más sensato: ¿mantener el tamaño de los filtros usados anteriormente? o ¿usar filtros más grandes en la segunda capa convolucional y más pequeños en la primera? o ¿usar filtros más pequeños en la segunda capa convolucional y más grandes en la primera? Hint: con esta nueva arquitectura debiese superar el 70% de accuracy (de validación/test) antes de 5 epochs, pero la arquitectura es más sensible a overfitting por lo que podrı́a ser conveniente agregar un regularizador. Como resultado final de esta actividad gráficque los errores de entrenamiento, validación y pruebas como función del número de “epochs” (fijando el máximo en un número razonable como T = 25).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doble capa de convolución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_convolutional_for_g():\n",
    "    model = Sequential()\n",
    "    \n",
    "    # C\n",
    "    model.add(Conv2D(64, (3, 3), padding='same', input_shape=x_train.shape[1:]))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    # C\n",
    "    model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    # P\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "     # C\n",
    "    model.add(Conv2D(128, (3, 3), padding='same', input_shape=x_train.shape[1:]))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    # C\n",
    "    model.add(Conv2D(128, (3, 3), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    # P\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    # F\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    # F\n",
    "    model.add(Dense(10))\n",
    "    model.add(Activation('softmax'))\n",
    "    return model\n",
    "\n",
    "define_convolutional_for_g().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = define_convolutional_for_g()\n",
    "opt = rmsprop(lr=0.001, decay=1e-6)\n",
    "model.compile(optimizer=opt, loss=\"categorical_crossentropy\", metrics=[\"acc\"])\n",
    "history = model.fit(x_train, y_train,batch_size=32,epochs=25, validation_data=(x_test, y_test),shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "h)Algunos investigadores, han propuesto que las capas de pooling se pueden reemplazar por capas convoluciones con stride 2. ¿Se reduce dimensionalidad de este modo? Compruébelo verificando los cambios de forma (dimensionalidad) que experimenta un patrón de entrada a medida que se ejecuta un forward-pass. Entrene la red resultante con el método que prefiera, gráficando los errores de entrenamiento, validación y pruebas como función del número de “epochs” (fijando el máximo en un número razonable como T = 25)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilización de convolución con strides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_convolutional_for_h():\n",
    "    model = Sequential()\n",
    "    \n",
    "    # C\n",
    "    model.add(Conv2D(64, (3, 3), padding='same', input_shape=x_train.shape[1:]))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    # C\n",
    "    model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    # C_STRIDE\n",
    "    model.add(Conv2D(64, (3, 3), strides=(2, 2), padding='same'))\n",
    "    \n",
    "     # C\n",
    "    model.add(Conv2D(128, (3, 3), padding='same', input_shape=x_train.shape[1:]))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    # C\n",
    "    model.add(Conv2D(128, (3, 3), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    # C_STRIDE\n",
    "    model.add(Conv2D(128, (3, 3), strides=(2, 2), padding='same'))\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    # F\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    # F\n",
    "    model.add(Dense(10))\n",
    "    model.add(Activation('softmax'))\n",
    "    return model\n",
    "define_convolutional_for_h().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = define_convolutional_for_h()\n",
    "opt = rmsprop(lr=0.001, decay=1e-6)\n",
    "model.compile(optimizer=opt, loss=\"categorical_crossentropy\", metrics=[\"acc\"])\n",
    "history = model.fit(x_train, y_train,batch_size=32,epochs=25, validation_data=(x_test, y_test),shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i) Una forma interesante de regularizar modelos entrenados para visión artificial consiste en “aumentar” el número de ejemplos de entrenamiento usando transformaciones sencillas como: rotaciones, corrimientos y reflexiones, tanto horizontales como verticales. Explique porqué este procedimiento podrı́a ayudar a mejorar el modelo y el porqué las etiquetas no cambian al aplicar estas operaciones. Evalúe experimentalmente la conveniencia de incorporarlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False, # set input mean to 0 over the dataset\n",
    "    samplewise_center=False, # set each sample mean to 0\n",
    "    featurewise_std_normalization=False, # divide inputs by std of the dataset\n",
    "    samplewise_std_normalization=False, # divide each input by its std\n",
    "    zca_whitening=False, # apply ZCA whitening\n",
    "    rotation_range=0, # randomly rotate images (degrees, 0 to 180)\n",
    "    width_shift_range=0.1, # randomly shift images horizontally (fraction of width)\n",
    "    height_shift_range=0.1, # randomly shift images vertically (fraction of height)\n",
    "    horizontal_flip=True, # randomly flip images\n",
    "    vertical_flip=False) # randomly flip images\n",
    "datagen.fit(x_train)\n",
    "\n",
    "\n",
    "model = define_convolutional()\n",
    "opt = rmsprop(lr=0.001, decay=1e-6)\n",
    "model.compile(optimizer=opt, loss=\"categorical_crossentropy\", metrics=[\"acc\"])\n",
    "history = model.fit(x_train, y_train,batch_size=32,epochs=25, validation_data=(x_test, y_test),shuffle=True)\n",
    "model.compile()\n",
    "\n",
    "batch_size = 32\n",
    "model.fit_generator(datagen.flow(x_train, y_train,batch_size=batch_size),steps_per_epoch=x_train.shape[0]// batch_size, epochs=25,validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "j)Elija una de las redes entrenadas en esta sección (preferentemente una con buen desempeño) y determine los pares de objetos (por ejemplo “camiones” con “autos”) que la red tiende a confundir. Conjeture el motivo de tal confusión. **Hay que hacer una matriz de confusión**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k)Elija una de las redes entrenadas (preferentemente una con buen desempeño) y visualice los pesos correspondientes a los filtros de la primera capa convolucional. Visualice además el efecto del filtro sobre algunas imágenes de entrenamiento. Repita el proceso para los pesos de la última capa convolucional. Comente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
